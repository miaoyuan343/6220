{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1d4ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def cardinality_items( filename ):\n",
    "    \n",
    "    #Takes a filename \"*.csv\" and returns an integer\n",
    "\n",
    "    unique= set()\n",
    "    with open('basket_data.csv', newline='') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            for item in row:\n",
    "                unique.add(item)\n",
    "    global uni\n",
    "    uni=list(unique)\n",
    "    return len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "970cd1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['bread', ' diapers', ' raisins', ' sausages', ' corn', ' bread', ' beans', ' chips', ' salmon', ' beer', 'ketchup', ' asparagus', ' pork', ' ketchup', 'okra', 'diapers', ' leeks', ' squid', 'butter', ' milk', ' spinach', ' tomotes', ' okra', ' butter', 'beer', ' spaghetti', ' macaroni']\n"
     ]
    }
   ],
   "source": [
    "print(cardinality_items('basket_data.csv'))\n",
    "print(uni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa009399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bread', ' diapers'], ['bread', ' raisins'], ['bread', ' sausages'], ['bread', ' corn'], ['bread', ' bread'], ['bread', ' beans'], ['bread', ' chips'], ['bread', ' salmon'], ['bread', ' beer'], ['bread', 'ketchup'], ['bread', ' asparagus'], ['bread', ' pork'], ['bread', ' ketchup'], ['bread', 'okra'], ['bread', 'diapers'], ['bread', ' leeks'], ['bread', ' squid'], ['bread', 'butter'], ['bread', ' milk'], ['bread', ' spinach'], ['bread', ' tomotes'], ['bread', ' okra'], ['bread', ' butter'], ['bread', 'beer'], ['bread', ' spaghetti'], ['bread', ' macaroni'], [' diapers', ' raisins'], [' diapers', ' sausages'], [' diapers', ' corn'], [' diapers', ' bread'], [' diapers', ' beans'], [' diapers', ' chips'], [' diapers', ' salmon'], [' diapers', ' beer'], [' diapers', 'ketchup'], [' diapers', ' asparagus'], [' diapers', ' pork'], [' diapers', ' ketchup'], [' diapers', 'okra'], [' diapers', 'diapers'], [' diapers', ' leeks'], [' diapers', ' squid'], [' diapers', 'butter'], [' diapers', ' milk'], [' diapers', ' spinach'], [' diapers', ' tomotes'], [' diapers', ' okra'], [' diapers', ' butter'], [' diapers', 'beer'], [' diapers', ' spaghetti'], [' diapers', ' macaroni'], [' raisins', ' sausages'], [' raisins', ' corn'], [' raisins', ' bread'], [' raisins', ' beans'], [' raisins', ' chips'], [' raisins', ' salmon'], [' raisins', ' beer'], [' raisins', 'ketchup'], [' raisins', ' asparagus'], [' raisins', ' pork'], [' raisins', ' ketchup'], [' raisins', 'okra'], [' raisins', 'diapers'], [' raisins', ' leeks'], [' raisins', ' squid'], [' raisins', 'butter'], [' raisins', ' milk'], [' raisins', ' spinach'], [' raisins', ' tomotes'], [' raisins', ' okra'], [' raisins', ' butter'], [' raisins', 'beer'], [' raisins', ' spaghetti'], [' raisins', ' macaroni'], [' sausages', ' corn'], [' sausages', ' bread'], [' sausages', ' beans'], [' sausages', ' chips'], [' sausages', ' salmon'], [' sausages', ' beer'], [' sausages', 'ketchup'], [' sausages', ' asparagus'], [' sausages', ' pork'], [' sausages', ' ketchup'], [' sausages', 'okra'], [' sausages', 'diapers'], [' sausages', ' leeks'], [' sausages', ' squid'], [' sausages', 'butter'], [' sausages', ' milk'], [' sausages', ' spinach'], [' sausages', ' tomotes'], [' sausages', ' okra'], [' sausages', ' butter'], [' sausages', 'beer'], [' sausages', ' spaghetti'], [' sausages', ' macaroni'], [' corn', ' bread'], [' corn', ' beans'], [' corn', ' chips'], [' corn', ' salmon'], [' corn', ' beer'], [' corn', 'ketchup'], [' corn', ' asparagus'], [' corn', ' pork'], [' corn', ' ketchup'], [' corn', 'okra'], [' corn', 'diapers'], [' corn', ' leeks'], [' corn', ' squid'], [' corn', 'butter'], [' corn', ' milk'], [' corn', ' spinach'], [' corn', ' tomotes'], [' corn', ' okra'], [' corn', ' butter'], [' corn', 'beer'], [' corn', ' spaghetti'], [' corn', ' macaroni'], [' bread', ' beans'], [' bread', ' chips'], [' bread', ' salmon'], [' bread', ' beer'], [' bread', 'ketchup'], [' bread', ' asparagus'], [' bread', ' pork'], [' bread', ' ketchup'], [' bread', 'okra'], [' bread', 'diapers'], [' bread', ' leeks'], [' bread', ' squid'], [' bread', 'butter'], [' bread', ' milk'], [' bread', ' spinach'], [' bread', ' tomotes'], [' bread', ' okra'], [' bread', ' butter'], [' bread', 'beer'], [' bread', ' spaghetti'], [' bread', ' macaroni'], [' beans', ' chips'], [' beans', ' salmon'], [' beans', ' beer'], [' beans', 'ketchup'], [' beans', ' asparagus'], [' beans', ' pork'], [' beans', ' ketchup'], [' beans', 'okra'], [' beans', 'diapers'], [' beans', ' leeks'], [' beans', ' squid'], [' beans', 'butter'], [' beans', ' milk'], [' beans', ' spinach'], [' beans', ' tomotes'], [' beans', ' okra'], [' beans', ' butter'], [' beans', 'beer'], [' beans', ' spaghetti'], [' beans', ' macaroni'], [' chips', ' salmon'], [' chips', ' beer'], [' chips', 'ketchup'], [' chips', ' asparagus'], [' chips', ' pork'], [' chips', ' ketchup'], [' chips', 'okra'], [' chips', 'diapers'], [' chips', ' leeks'], [' chips', ' squid'], [' chips', 'butter'], [' chips', ' milk'], [' chips', ' spinach'], [' chips', ' tomotes'], [' chips', ' okra'], [' chips', ' butter'], [' chips', 'beer'], [' chips', ' spaghetti'], [' chips', ' macaroni'], [' salmon', ' beer'], [' salmon', 'ketchup'], [' salmon', ' asparagus'], [' salmon', ' pork'], [' salmon', ' ketchup'], [' salmon', 'okra'], [' salmon', 'diapers'], [' salmon', ' leeks'], [' salmon', ' squid'], [' salmon', 'butter'], [' salmon', ' milk'], [' salmon', ' spinach'], [' salmon', ' tomotes'], [' salmon', ' okra'], [' salmon', ' butter'], [' salmon', 'beer'], [' salmon', ' spaghetti'], [' salmon', ' macaroni'], [' beer', 'ketchup'], [' beer', ' asparagus'], [' beer', ' pork'], [' beer', ' ketchup'], [' beer', 'okra'], [' beer', 'diapers'], [' beer', ' leeks'], [' beer', ' squid'], [' beer', 'butter'], [' beer', ' milk'], [' beer', ' spinach'], [' beer', ' tomotes'], [' beer', ' okra'], [' beer', ' butter'], [' beer', 'beer'], [' beer', ' spaghetti'], [' beer', ' macaroni'], ['ketchup', ' asparagus'], ['ketchup', ' pork'], ['ketchup', ' ketchup'], ['ketchup', 'okra'], ['ketchup', 'diapers'], ['ketchup', ' leeks'], ['ketchup', ' squid'], ['ketchup', 'butter'], ['ketchup', ' milk'], ['ketchup', ' spinach'], ['ketchup', ' tomotes'], ['ketchup', ' okra'], ['ketchup', ' butter'], ['ketchup', 'beer'], ['ketchup', ' spaghetti'], ['ketchup', ' macaroni'], [' asparagus', ' pork'], [' asparagus', ' ketchup'], [' asparagus', 'okra'], [' asparagus', 'diapers'], [' asparagus', ' leeks'], [' asparagus', ' squid'], [' asparagus', 'butter'], [' asparagus', ' milk'], [' asparagus', ' spinach'], [' asparagus', ' tomotes'], [' asparagus', ' okra'], [' asparagus', ' butter'], [' asparagus', 'beer'], [' asparagus', ' spaghetti'], [' asparagus', ' macaroni'], [' pork', ' ketchup'], [' pork', 'okra'], [' pork', 'diapers'], [' pork', ' leeks'], [' pork', ' squid'], [' pork', 'butter'], [' pork', ' milk'], [' pork', ' spinach'], [' pork', ' tomotes'], [' pork', ' okra'], [' pork', ' butter'], [' pork', 'beer'], [' pork', ' spaghetti'], [' pork', ' macaroni'], [' ketchup', 'okra'], [' ketchup', 'diapers'], [' ketchup', ' leeks'], [' ketchup', ' squid'], [' ketchup', 'butter'], [' ketchup', ' milk'], [' ketchup', ' spinach'], [' ketchup', ' tomotes'], [' ketchup', ' okra'], [' ketchup', ' butter'], [' ketchup', 'beer'], [' ketchup', ' spaghetti'], [' ketchup', ' macaroni'], ['okra', 'diapers'], ['okra', ' leeks'], ['okra', ' squid'], ['okra', 'butter'], ['okra', ' milk'], ['okra', ' spinach'], ['okra', ' tomotes'], ['okra', ' okra'], ['okra', ' butter'], ['okra', 'beer'], ['okra', ' spaghetti'], ['okra', ' macaroni'], ['diapers', ' leeks'], ['diapers', ' squid'], ['diapers', 'butter'], ['diapers', ' milk'], ['diapers', ' spinach'], ['diapers', ' tomotes'], ['diapers', ' okra'], ['diapers', ' butter'], ['diapers', 'beer'], ['diapers', ' spaghetti'], ['diapers', ' macaroni'], [' leeks', ' squid'], [' leeks', 'butter'], [' leeks', ' milk'], [' leeks', ' spinach'], [' leeks', ' tomotes'], [' leeks', ' okra'], [' leeks', ' butter'], [' leeks', 'beer'], [' leeks', ' spaghetti'], [' leeks', ' macaroni'], [' squid', 'butter'], [' squid', ' milk'], [' squid', ' spinach'], [' squid', ' tomotes'], [' squid', ' okra'], [' squid', ' butter'], [' squid', 'beer'], [' squid', ' spaghetti'], [' squid', ' macaroni'], ['butter', ' milk'], ['butter', ' spinach'], ['butter', ' tomotes'], ['butter', ' okra'], ['butter', ' butter'], ['butter', 'beer'], ['butter', ' spaghetti'], ['butter', ' macaroni'], [' milk', ' spinach'], [' milk', ' tomotes'], [' milk', ' okra'], [' milk', ' butter'], [' milk', 'beer'], [' milk', ' spaghetti'], [' milk', ' macaroni'], [' spinach', ' tomotes'], [' spinach', ' okra'], [' spinach', ' butter'], [' spinach', 'beer'], [' spinach', ' spaghetti'], [' spinach', ' macaroni'], [' tomotes', ' okra'], [' tomotes', ' butter'], [' tomotes', 'beer'], [' tomotes', ' spaghetti'], [' tomotes', ' macaroni'], [' okra', ' butter'], [' okra', 'beer'], [' okra', ' spaghetti'], [' okra', ' macaroni'], [' butter', 'beer'], [' butter', ' spaghetti'], [' butter', ' macaroni'], ['beer', ' spaghetti'], ['beer', ' macaroni'], [' spaghetti', ' macaroni']]\n"
     ]
    }
   ],
   "source": [
    "def all_itemsets(items, N):\n",
    "    result = []\n",
    "\n",
    "    def generate_itemsets(current_itemset, remaining_items, N):\n",
    "        if N == 0:\n",
    "            result.append(current_itemset)\n",
    "            return\n",
    "        if not remaining_items:\n",
    "            return\n",
    "        generate_itemsets(current_itemset + [remaining_items[0]], remaining_items[1:], N - 1)\n",
    "        generate_itemsets(current_itemset, remaining_items[1:], N)\n",
    "\n",
    "    generate_itemsets([], items, N)  \n",
    "    return result\n",
    "\n",
    "\n",
    "##itemsets = all_itemsets(uni, 2)\n",
    "##print(itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ef3e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100498273\n"
     ]
    }
   ],
   "source": [
    "combine=[]\n",
    "combine.append(pd.read_csv('combined_data_1.txt',delimiter=',',names=['user','rate','time'],skiprows=1))\n",
    "combine.append(pd.read_csv('combined_data_2.txt',delimiter=',',names=['user','rate','time'],skiprows=1))\n",
    "combine.append(pd.read_csv('combined_data_3.txt',delimiter=',',names=['user','rate','time'],skiprows=1))\n",
    "combine.append(pd.read_csv('combined_data_4.txt',delimiter=',',names=['user','rate','time'],skiprows=1))\n",
    "df= pd.concat(combine, ignore_index=True)\n",
    "\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab6b7a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user    497955\n",
      "rate         5\n",
      "time      2182\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_user=df.nunique()\n",
    "print(unique_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e002349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user  rate        time\n",
      "0  1488844   3.0  2005-09-06\n",
      "1   822109   5.0  2005-05-13\n",
      "2   885013   4.0  2005-10-19\n",
      "3    30878   4.0  2005-12-26\n",
      "4   823519   3.0  2004-05-03\n",
      "5   893988   3.0  2005-11-17\n",
      "6   124105   4.0  2004-08-05\n",
      "7  1248029   3.0  2004-04-22\n",
      "8  1842128   4.0  2004-05-09\n",
      "9  2238063   3.0  2005-05-11\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7ca300e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11965\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.min\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11945\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11946\u001b[0m     _num_doc,\n\u001b[1;32m  11947\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the minimum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11963\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11964\u001b[0m ):\n\u001b[0;32m> 11965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11365\u001b[0m, in \u001b[0;36mNDFrame.min\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(\n\u001b[1;32m  11358\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11359\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11364\u001b[0m ):\n\u001b[0;32m> 11365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  11366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m  11367\u001b[0m         nanops\u001b[38;5;241m.\u001b[39mnanmin,\n\u001b[1;32m  11368\u001b[0m         axis,\n\u001b[1;32m  11369\u001b[0m         skipna,\n\u001b[1;32m  11370\u001b[0m         level,\n\u001b[1;32m  11371\u001b[0m         numeric_only,\n\u001b[1;32m  11372\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11373\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  11354\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11355\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1051\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1051\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(values, meth)(axis)\n\u001b[1;32m   1053\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:45\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "print(df['time'].min())\n",
    "print(df['time'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a09dd4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17297 movies with unique names.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_movie_titles = set()\n",
    "\n",
    "# Open and read the \"movie_titles.csv\" file with 'latin-1' encoding\n",
    "with open(\"movie_titles.csv\", newline='', encoding='latin-1') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "\n",
    "\n",
    "    for row in reader:\n",
    "        title = row[2]\n",
    "\n",
    "        # Add the movie title to the set\n",
    "        unique_movie_titles.add(title)\n",
    "\n",
    "# Calculate the number of unique movie titles\n",
    "num_unique_movies = len(unique_movie_titles)\n",
    "\n",
    "print(f\"There are {num_unique_movies} movies with unique names.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "405d707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 movie names that refer to four different movies.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Create a dictionary to store the count of each movie title\n",
    "movie_title_counts = Counter()\n",
    "\n",
    "with open(\"movie_titles.csv\", newline='', encoding='latin-1') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    \n",
    "\n",
    "    for row in reader:\n",
    "        title = row[2]\n",
    "\n",
    "        # Count the occurrence of each movie title\n",
    "        movie_title_counts[title] += 1\n",
    "\n",
    "# Find movie titles that appear exactly four times\n",
    "four_occurrence_titles = [title for title, count in movie_title_counts.items() if count == 4]\n",
    "\n",
    "# Calculate the number of movie names that refer to four different movies\n",
    "num_titles_refer_to_four_movies = len(four_occurrence_titles)\n",
    "\n",
    "print(f\"There are {num_titles_refer_to_four_movies} movie names that refer to four different movies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409d67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
